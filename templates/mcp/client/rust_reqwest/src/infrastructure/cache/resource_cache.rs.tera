//! SQLite-powered resource caching system for {{ project_name }}
//!
//! {{ description }}
//! that goes beyond simple key-value storage to offer a full-featured resource database
//! with structured storage, rich queries, ACID transactions, and built-in analytics.
//!
//! Version: {{ version }}
//! Cache TTL: 300 seconds
//! Max Cache Size: 1000 MB

use crate::infrastructure::database::manager::DatabaseManager;
use crate::infrastructure::error::{ClientError, Result};
use crate::api::resource::{ResourceContent, ResourceInfo};
use chrono::{DateTime, Utc};
use rusqlite::{OptionalExtension, params};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;
use std::time::Duration;
use tracing::{debug, info, warn};
use uuid::Uuid;

/// Configuration for the resource cache
#[derive(Debug, Clone)]
pub struct CacheConfig {
    /// Default TTL for cached resources
    pub default_ttl: Duration,
    /// Maximum cache size in MB (0 = unlimited)
    pub max_size_mb: u64,
    /// Enable automatic cleanup of expired resources
    pub auto_cleanup: bool,
}

impl Default for CacheConfig {
    fn default() -> Self {
        Self {
            default_ttl: Duration::from_secs(300), // Default cache TTL
            max_size_mb: 1000,                     // Max cache size
            auto_cleanup: true,
        }
    }
}

/// Cache analytics and performance metrics
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CacheAnalytics {
    /// Total cache requests
    pub total_requests: u64,
    /// Cache hits
    pub cache_hits: u64,
    /// Cache misses
    pub cache_misses: u64,
    /// Total size of cached data in MB
    pub total_size_mb: f64,
    /// Number of evictions
    pub eviction_count: u64,
    /// Average response time in milliseconds
    pub avg_response_time_ms: f64,
}

impl CacheAnalytics {
    /// Create new analytics instance
    pub fn new() -> Self {
        Self {
            total_requests: 0,
            cache_hits: 0,
            cache_misses: 0,
            total_size_mb: 0.0,
            eviction_count: 0,
            avg_response_time_ms: 0.0,
        }
    }

    /// Calculate hit rate as a percentage
    pub fn hit_rate(&self) -> f64 {
        if self.total_requests == 0 {
            0.0
        } else {
            (self.cache_hits as f64 / self.total_requests as f64) * 100.0
        }
    }
}

/// Cached resource metadata
///
/// Represents a resource stored in the SQLite cache with full metadata
/// for tracking access patterns, expiration, and storage efficiency.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CachedResource {
    /// Unique resource identifier (UUID v4)
    /// Used as the primary key in the SQLite database
    pub id: String,

    /// Resource URI (e.g., "/schema/pet", "https://api.example.com/data")
    /// This is the key used for lookups and must be unique in the cache
    pub uri: String,

    /// MIME type or content classification (e.g., "text", "binary")
    /// Used to determine how to decode and present the cached data
    pub content_type: Option<String>,

    /// Timestamp when this resource was first cached
    /// Used for cache age analysis and cleanup policies
    pub created_at: DateTime<Utc>,

    /// Timestamp of the most recent access to this resource
    /// Updated on every cache hit to support LRU eviction
    pub accessed_at: DateTime<Utc>,

    /// Optional expiration timestamp for this resource
    /// Resources are automatically removed after this time
    pub expires_at: Option<DateTime<Utc>>,

    /// Number of times this resource has been accessed
    /// Used for analytics and hot-resource identification
    pub access_count: u64,

    /// Size of the cached content in bytes
    /// Used for storage management and eviction decisions
    pub size_bytes: u64,
}

/// SQLite-backed resource cache with advanced features
///
/// Provides high-performance caching for MCP resources using SQLite as the
/// storage backend. Features include:
/// - Automatic expiration and TTL management
/// - LRU eviction when size limits are exceeded
/// - Built-in analytics for cache performance monitoring
/// - Thread-safe operations via connection pooling
/// - Atomic transactions for data integrity
#[derive(Debug)]
pub struct ResourceCache {
    /// Cache configuration (TTL, size limits, auto-cleanup settings)
    config: CacheConfig,

    /// In-memory analytics for real-time performance tracking
    /// Updated on every cache operation without database overhead
    analytics: CacheAnalytics,

    /// Shared database manager providing connection pooling and
    /// thread-safe access to the underlying SQLite database
    db: Arc<DatabaseManager>,
}

impl ResourceCache {
    /// Create a new resource cache using the shared database
    ///
    /// # Arguments
    /// * `config` - Cache configuration including TTL and size limits
    /// * `db` - Shared database manager for SQLite operations
    ///
    /// # Returns
    /// A new ResourceCache instance ready for use
    pub async fn new(config: CacheConfig, db: Arc<DatabaseManager>) -> Result<Self> {
        let analytics = CacheAnalytics::new();

        let cache = Self {
            config,
            analytics,
            db,
        };

        info!("Resource cache initialized successfully");
        Ok(cache)
    }

    /// Store a resource in the cache with automatic expiration
    ///
    /// # Arguments
    /// * `resource` - The resource content to cache, including data and metadata
    ///
    /// # Behavior
    /// - Generates a unique ID for the resource
    /// - Sets expiration based on configured TTL
    /// - Triggers automatic cleanup if size limits are exceeded
    /// - Updates analytics for cache size tracking
    ///
    /// # Errors
    /// Returns an error if database operations fail or serialization fails
    pub async fn store_resource(&mut self, resource: &ResourceContent) -> Result<()> {
        let id = Uuid::new_v4().to_string();
        let now = Utc::now();
        let expires_at = now + chrono::Duration::from_std(self.config.default_ttl)
            .map_err(|e| ClientError::Client(format!("Invalid TTL duration: {}", e)))?;

        // Serialize metadata
        let metadata_json = serde_json::to_string(&resource.info.metadata)
            .map_err(|e| ClientError::Client(format!("Failed to serialize metadata: {}", e)))?;

        // Determine content type
        let content_type = match &resource.encoding {
            Some(_) => "text",
            None => "binary",
        };

        let size_bytes = resource.data.len() as i64;
        let now_ts = now.timestamp_millis();
        let expires_ts = expires_at.timestamp_millis();

        // Clone necessary data for 'static lifetime requirement
        let uri_clone = resource.info.uri.clone();
        let data_clone = resource.data.clone();
        let content_type_str = content_type.to_string();
        let metadata_clone = metadata_json.clone();

        self.db.with_connection(move |conn| {
            conn.execute(
                "INSERT OR REPLACE INTO resources
                 (id, uri, content, content_type, metadata_json, created_at, accessed_at, expires_at, access_count, size_bytes)
                 VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10)",
                params![
                    id,
                    uri_clone,
                    data_clone,
                    content_type_str,
                    metadata_clone,
                    now_ts,
                    now_ts,
                    expires_ts,
                    0,
                    size_bytes
                ],
            )?;
            Ok(())
        }).await?;

        // Update analytics
        self.analytics.total_size_mb += (size_bytes as f64) / (1024.0 * 1024.0);

        // Clean up if auto cleanup is enabled
        if self.config.auto_cleanup {
            self.cleanup_if_needed().await?;
        }

        debug!(
            "Cached resource: {} ({} bytes)",
            resource.info.uri, size_bytes
        );
        Ok(())
    }

    /// Retrieve a resource from cache with automatic expiration checking
    ///
    /// # Arguments
    /// * `uri` - The resource URI to look up (must match exactly)
    ///
    /// # Returns
    /// - `Some(ResourceContent)` if found and not expired
    /// - `None` if not found or expired
    ///
    /// # Behavior
    /// - Checks expiration and removes expired entries automatically
    /// - Updates access count and last accessed timestamp on hits
    /// - Tracks analytics for hit/miss rates and response times
    /// - Thread-safe via connection pooling
    ///
    /// # Example
    /// ```rust,no_run
    /// # use {{ crate_name }}::cache::{ResourceCache, CacheConfig};
    /// # use {{ crate_name }}::database::DatabaseManager;
    /// # use std::sync::Arc;
    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// # let db = Arc::new(DatabaseManager::new().await?);
    /// # let mut cache = ResourceCache::new(CacheConfig::default(), db).await?;
    /// if let Some(resource) = cache.get_resource("/api/users").await? {
    ///     println!("Cache hit! Data: {} bytes", resource.data.len());
    /// }
    /// # Ok(())
    /// # }
    /// ```
    pub async fn get_resource(&mut self, uri: &str) -> Result<Option<ResourceContent>> {
        let start_time = std::time::Instant::now();

        #[derive(Debug)]
        struct CacheRow {
            id: String,
            content: Vec<u8>,
            content_type: String,
            metadata_json: String,
            expires_at: i64,
            access_count: i64,
        }

        let uri_clone = uri.to_string();
        let result: Option<CacheRow> = self
            .db
            .with_connection(move |conn| {
                let mut stmt = conn.prepare(
                    "SELECT id, content, content_type, metadata_json, expires_at, access_count
                 FROM resources
                 WHERE uri = ?1",
                )?;

                let resource = stmt
                    .query_row(params![uri_clone], |row| {
                        Ok(CacheRow {
                            id: row.get(0)?,
                            content: row.get(1)?,
                            content_type: row.get(2)?,
                            metadata_json: row.get(3)?,
                            expires_at: row.get(4)?,
                            access_count: row.get(5)?,
                        })
                    })
                    .optional()?;

                Ok(resource)
            })
            .await?;

        match result {
            Some(row) => {
                // Parse expiration timestamp - treat invalid timestamps as corruption
                let expires_dt = DateTime::from_timestamp_millis(row.expires_at)
                    .ok_or_else(|| ClientError::Client(format!(
                        "Invalid expiration timestamp {} for resource '{}'", 
                        row.expires_at, uri
                    )))?;

                // Check if expired
                if expires_dt < Utc::now() {
                    self.analytics.cache_misses += 1;
                    self.analytics.total_requests += 1;
                    debug!("Cache miss (expired): {}", uri);

                    // Remove expired entry
                    self.remove_resource(uri).await?;
                    return Ok(None);
                }

                // Update access time and count
                let now = Utc::now();
                let id_clone = row.id.clone();
                let new_access_count = row.access_count + 1;
                self.db
                    .with_connection(move |conn| {
                        conn.execute(
                        "UPDATE resources SET accessed_at = ?1, access_count = ?2 WHERE id = ?3",
                        params![now.timestamp_millis(), new_access_count, id_clone],
                    )?;
                        Ok(())
                    })
                    .await?;

                // Deserialize metadata
                let metadata: HashMap<String, serde_json::Value> =
                    serde_json::from_str(&row.metadata_json).unwrap_or_default();

                // Reconstruct ResourceContent
                let resource_info = ResourceInfo {
                    uri: uri.to_string(),
                    name: metadata
                        .get("name")
                        .and_then(|v| v.as_str())
                        .map(String::from),
                    description: metadata
                        .get("description")
                        .and_then(|v| v.as_str())
                        .map(String::from),
                    mime_type: metadata
                        .get("mime_type")
                        .and_then(|v| v.as_str())
                        .map(String::from),
                    metadata,
                };

                let encoding = if row.content_type == "text" {
                    Some("utf-8".to_string())
                } else {
                    None
                };

                let resource_content = ResourceContent {
                    info: resource_info,
                    data: row.content,
                    encoding,
                };

                self.analytics.cache_hits += 1;
                self.analytics.total_requests += 1;
                let elapsed = start_time.elapsed().as_millis() as f64;
                self.update_avg_response_time(elapsed);

                debug!("Cache hit: {} (access count: {})", uri, new_access_count);
                Ok(Some(resource_content))
            }
            None => {
                self.analytics.cache_misses += 1;
                self.analytics.total_requests += 1;
                debug!("Cache miss: {}", uri);
                Ok(None)
            }
        }
    }

    /// Remove a specific resource from cache
    pub async fn remove_resource(&mut self, uri: &str) -> Result<()> {
        let uri_clone = uri.to_string();
        let removed_size = self
            .db
            .with_connection(move |conn| {
                // Get size before deletion
                let size: Result<i64> = conn
                    .query_row(
                        "SELECT size_bytes FROM resources WHERE uri = ?1",
                        params![uri_clone.clone()],
                        |row| row.get(0),
                    )
                    .map_err(|e| {
                        ClientError::Client(format!("Failed to get resource size: {}", e))
                    });

                let size_bytes = size.unwrap_or(0);

                // Delete the resource
                conn.execute("DELETE FROM resources WHERE uri = ?1", params![uri_clone])?;

                Ok(size_bytes)
            })
            .await?;

        // Update analytics
        if removed_size > 0 {
            self.analytics.total_size_mb -= (removed_size as f64) / (1024.0 * 1024.0);
            self.analytics.eviction_count += 1;
        }

        debug!("Removed resource from cache: {}", uri);
        Ok(())
    }

    /// Clear all cached resources
    pub async fn clear(&mut self) -> Result<()> {
        self.db
            .with_connection(|conn| {
                conn.execute("DELETE FROM resources", [])?;
                Ok(())
            })
            .await?;

        // Reset analytics
        self.analytics.total_size_mb = 0.0;
        self.analytics.eviction_count = 0;

        info!("Cache cleared");
        Ok(())
    }

    /// Clean up expired resources
    pub async fn cleanup_expired(&mut self) -> Result<u64> {
        let now = Utc::now();

        let result = self
            .db
            .with_connection(move |conn| {
                // Get total size of expired resources
                let total_size: i64 = conn.query_row(
                    "SELECT COALESCE(SUM(size_bytes), 0) FROM resources WHERE expires_at < ?1",
                    params![now.timestamp_millis()],
                    |row| row.get(0),
                )?;

                // Delete expired resources
                let deleted = conn.execute(
                    "DELETE FROM resources WHERE expires_at < ?1",
                    params![now.timestamp_millis()],
                )?;

                Ok((deleted as u64, total_size))
            })
            .await?;

        let (deleted_count, deleted_size) = result;

        if deleted_count > 0 {
            self.analytics.total_size_mb -= (deleted_size as f64) / (1024.0 * 1024.0);
            self.analytics.eviction_count += deleted_count;
            info!(
                "Cleaned up {} expired resources ({:.2} MB)",
                deleted_count,
                (deleted_size as f64) / (1024.0 * 1024.0)
            );
        }

        Ok(deleted_count)
    }

    /// Get cache analytics
    pub fn get_analytics(&self) -> &CacheAnalytics {
        &self.analytics
    }

    /// Get list of cached resources
    pub async fn list_cached_resources(&self) -> Result<Vec<CachedResource>> {
        self.db.with_connection(|conn| {
            let mut stmt = conn.prepare(
                "SELECT id, uri, content_type, created_at, accessed_at, expires_at, access_count, size_bytes
                 FROM resources
                 ORDER BY accessed_at DESC"
            )?;

            let resources = stmt.query_map([], |row| {
                Ok(CachedResource {
                    id: row.get(0)?,
                    uri: row.get(1)?,
                    content_type: row.get(2)?,
                    created_at: DateTime::from_timestamp_millis(row.get(3)?)
                        .unwrap_or_else(Utc::now),
                    accessed_at: DateTime::from_timestamp_millis(row.get(4)?)
                        .unwrap_or_else(Utc::now),
                    expires_at: row.get::<_, Option<i64>>(5)?
                        .and_then(DateTime::from_timestamp_millis),
                    access_count: row.get::<_, i64>(6)? as u64,
                    size_bytes: row.get::<_, i64>(7)? as u64,
                })
            })?
            .collect::<std::result::Result<Vec<_>, _>>()?;

            Ok(resources)
        }).await
    }

    /// Search cached resources by URI pattern
    pub async fn search_resources(&self, query: &str) -> Result<Vec<CachedResource>> {
        let pattern = format!("%{}%", query);

        self.db.with_connection(move |conn| {
            let mut stmt = conn.prepare(
                "SELECT id, uri, content_type, created_at, accessed_at, expires_at, access_count, size_bytes
                 FROM resources
                 WHERE uri LIKE ?1
                 ORDER BY accessed_at DESC"
            )?;

            let resources = stmt.query_map(params![pattern], |row| {
                Ok(CachedResource {
                    id: row.get(0)?,
                    uri: row.get(1)?,
                    content_type: row.get(2)?,
                    created_at: DateTime::from_timestamp_millis(row.get(3)?)
                        .unwrap_or_else(Utc::now),
                    accessed_at: DateTime::from_timestamp_millis(row.get(4)?)
                        .unwrap_or_else(Utc::now),
                    expires_at: row.get::<_, Option<i64>>(5)?
                        .and_then(DateTime::from_timestamp_millis),
                    access_count: row.get::<_, i64>(6)? as u64,
                    size_bytes: row.get::<_, i64>(7)? as u64,
                })
            })?
            .collect::<std::result::Result<Vec<_>, _>>()?;

            Ok(resources)
        }).await
    }

    /// Record analytics snapshot
    pub async fn record_analytics(&self) -> Result<()> {
        let analytics = self.analytics.clone();

        self.db.with_connection(move |conn| {
            conn.execute(
                "INSERT INTO cache_analytics (timestamp, hit_rate, total_requests, cache_size_mb, eviction_count)
                 VALUES (?1, ?2, ?3, ?4, ?5)",
                params![
                    Utc::now().timestamp_millis(),
                    analytics.hit_rate(),
                    analytics.total_requests as i64,
                    analytics.total_size_mb,
                    analytics.eviction_count as i64
                ],
            )?;
            Ok(())
        }).await?;

        debug!("Recorded analytics snapshot");
        Ok(())
    }

    // Private helper methods

    /// Update average response time
    fn update_avg_response_time(&mut self, new_time_ms: f64) {
        // Note: This is called AFTER incrementing total_requests, so we use the new count
        let total = self.analytics.total_requests as f64;
        
        if total <= 1.0 {
            // First request
            self.analytics.avg_response_time_ms = new_time_ms;
        } else {
            // Calculate new average using existing average
            let current_avg = self.analytics.avg_response_time_ms;
            self.analytics.avg_response_time_ms =
                ((current_avg * (total - 1.0)) + new_time_ms) / total;
        }
    }

    /// Clean up cache if size exceeds limit
    async fn cleanup_if_needed(&mut self) -> Result<()> {
        if self.config.max_size_mb == 0 {
            return Ok(()); // No size limit
        }

        let current_size_mb = self.analytics.total_size_mb;
        if current_size_mb <= self.config.max_size_mb as f64 {
            return Ok(()); // Within limits
        }

        // Need to evict oldest resources
        let excess_mb = current_size_mb - (self.config.max_size_mb as f64);
        let excess_bytes = (excess_mb * 1024.0 * 1024.0) as i64;

        warn!("Cache size exceeded limit by {:.2} MB, evicting oldest resources", excess_mb);

        let evicted = self.db.with_connection(move |conn| {
            // Find and delete oldest resources until we're under the limit
            let mut total_freed = 0i64;
            let mut evicted_count = 0u64;

            // Get oldest resources
            let mut stmt = conn.prepare(
                "SELECT id, uri, size_bytes FROM resources
                 ORDER BY accessed_at ASC
                 LIMIT 100"
            )?;

            let resources_to_evict: Vec<(String, String, i64)> = stmt.query_map([], |row| {
                Ok((row.get(0)?, row.get(1)?, row.get(2)?))
            })?
            .collect::<std::result::Result<Vec<_>, _>>()?;

            // Delete resources until we've freed enough space
            for (id, uri, size) in resources_to_evict {
                if total_freed >= excess_bytes {
                    break;
                }

                conn.execute("DELETE FROM resources WHERE id = ?1", params![id])?;
                total_freed += size;
                evicted_count += 1;
                debug!("Evicted resource: {} ({} bytes)", uri, size);
            }

            Ok((evicted_count, total_freed))
        }).await?;

        let (count, freed_bytes) = evicted;

        // Update analytics
        self.analytics.total_size_mb -= (freed_bytes as f64) / (1024.0 * 1024.0);
        self.analytics.eviction_count += count;

        info!(
            "Evicted {} resources to free {:.2} MB",
            count,
            (freed_bytes as f64) / (1024.0 * 1024.0)
        );

        Ok(())
    }
}

impl Default for CacheAnalytics {
    fn default() -> Self {
        Self::new()
    }
}