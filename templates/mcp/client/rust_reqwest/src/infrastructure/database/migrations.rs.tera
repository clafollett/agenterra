//! Database migrations for {{ project_name }}
//! 
//! All schema migrations are defined here as constants and exposed
//! as a vector for rusqlite_migration to process.
//!
//! IMPORTANT: Never modify existing migrations! This will cause hash mismatches.
//! Always create new migrations to modify the schema.

use rusqlite_migration::M;
use std::collections::hash_map::DefaultHasher;
use std::hash::{Hash, Hasher};

/// Migration metadata for verification
#[derive(Debug, Clone)]
pub struct MigrationInfo {
    pub version: u32,
    pub name: &'static str,
    pub sql: &'static str,
    pub hash: u64,
}

impl MigrationInfo {
    const fn new(version: u32, name: &'static str, sql: &'static str) -> Self {
        // Calculate hash at compile time (const context limits us to simple hash)
        let bytes = sql.as_bytes();
        let mut hash = 0u64;
        let mut i = 0;
        while i < bytes.len() {
            hash = hash.wrapping_mul(31).wrapping_add(bytes[i] as u64);
            i += 1;
        }
        
        Self {
            version,
            name,
            sql,
            hash,
        }
    }
}

/// Calculate hash for a migration SQL string at runtime (for verification)
fn calculate_migration_hash(sql: &str) -> u64 {
    let mut hasher = DefaultHasher::new();
    sql.hash(&mut hasher);
    hasher.finish()
}

/// Initial schema - creates all base tables
const MIGRATION_001_INITIAL_SCHEMA: &str = r#"
-- Resources table for caching
CREATE TABLE resources (
    id TEXT PRIMARY KEY,
    uri TEXT UNIQUE NOT NULL,
    content BLOB NOT NULL,
    content_type TEXT,
    metadata_json TEXT,
    created_at INTEGER NOT NULL,
    accessed_at INTEGER NOT NULL,
    expires_at INTEGER,
    access_count INTEGER DEFAULT 0,
    size_bytes INTEGER NOT NULL
);

-- Indexes for performance
CREATE INDEX idx_resources_uri ON resources(uri);
CREATE INDEX idx_resources_expires ON resources(expires_at);
CREATE INDEX idx_resources_accessed ON resources(accessed_at);

-- Cache analytics
CREATE TABLE cache_analytics (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    event_type TEXT NOT NULL,
    resource_id TEXT,
    timestamp INTEGER NOT NULL,
    details TEXT,
    FOREIGN KEY (resource_id) REFERENCES resources(id) ON DELETE CASCADE
);

-- Configuration table
CREATE TABLE configuration (
    key TEXT PRIMARY KEY,
    value TEXT NOT NULL,
    updated_at INTEGER NOT NULL
);

-- Server management
CREATE TABLE servers (
    id TEXT PRIMARY KEY,
    transport TEXT NOT NULL CHECK(transport IN ('stdio', 'http')),
    location TEXT NOT NULL,
    name TEXT,
    arguments TEXT,
    environment_json TEXT,
    created_at INTEGER NOT NULL,
    last_used_at INTEGER
);

-- Server credentials
CREATE TABLE credentials (
    server_id TEXT PRIMARY KEY,
    credential_type TEXT NOT NULL,
    credential_data TEXT NOT NULL,
    created_at INTEGER NOT NULL,
    FOREIGN KEY (server_id) REFERENCES servers(id) ON DELETE CASCADE
);

-- Session management
CREATE TABLE sessions (
    id TEXT PRIMARY KEY,
    server_id TEXT NOT NULL,
    started_at INTEGER NOT NULL,
    ended_at INTEGER,
    metadata_json TEXT,
    FOREIGN KEY (server_id) REFERENCES servers(id) ON DELETE CASCADE
);

-- Tool call history
CREATE TABLE tool_calls (
    id TEXT PRIMARY KEY,
    session_id TEXT NOT NULL,
    tool_name TEXT NOT NULL,
    arguments_json TEXT,
    result_json TEXT,
    error TEXT,
    duration_ms INTEGER,
    timestamp INTEGER NOT NULL,
    FOREIGN KEY (session_id) REFERENCES sessions(id) ON DELETE CASCADE
);

-- User preferences
CREATE TABLE preferences (
    key TEXT PRIMARY KEY,
    value TEXT NOT NULL,
    category TEXT,
    updated_at INTEGER NOT NULL
);

-- Indexes for performance
CREATE INDEX idx_sessions_server ON sessions(server_id);
CREATE INDEX idx_tool_calls_session ON tool_calls(session_id);
CREATE INDEX idx_tool_calls_timestamp ON tool_calls(timestamp);
"#;

/// Add retry tracking for failed operations
const MIGRATION_002_ADD_RETRY_TRACKING: &str = r#"
-- Track failed operations for retry with exponential backoff
CREATE TABLE retry_queue (
    id TEXT PRIMARY KEY,
    operation_type TEXT NOT NULL CHECK(operation_type IN ('tool_call', 'resource_fetch', 'server_connect')),
    payload_json TEXT NOT NULL,
    retry_count INTEGER DEFAULT 0,
    max_retries INTEGER DEFAULT 3,
    last_attempt_at INTEGER,
    next_retry_at INTEGER NOT NULL,
    error_message TEXT,
    created_at INTEGER NOT NULL,
    completed_at INTEGER,
    status TEXT DEFAULT 'pending' CHECK(status IN ('pending', 'in_progress', 'completed', 'failed'))
);

-- Index for efficient polling of items ready to retry
CREATE INDEX idx_retry_queue_next ON retry_queue(next_retry_at) WHERE status = 'pending';

-- Index for cleanup of old completed/failed items
CREATE INDEX idx_retry_queue_status ON retry_queue(status, completed_at);
"#;

// Example future migrations (commented out until needed):
/*
/// Add tags support to resources
const MIGRATION_003_ADD_RESOURCE_TAGS: &str = r#"
-- Add tags to resources
ALTER TABLE resources ADD COLUMN tags TEXT;

-- Create tags lookup table for autocomplete
CREATE TABLE resource_tags (
    tag TEXT PRIMARY KEY,
    usage_count INTEGER DEFAULT 1,
    created_at INTEGER NOT NULL
);

-- Index for tag searches
CREATE INDEX idx_resources_tags ON resources(tags);
"#;
*/

/// All migrations with metadata for verification
pub const MIGRATIONS_INFO: &[MigrationInfo] = &[
    MigrationInfo::new(1, "initial_schema", MIGRATION_001_INITIAL_SCHEMA),
    MigrationInfo::new(2, "add_retry_tracking", MIGRATION_002_ADD_RETRY_TRACKING),
    // Future migrations would be added here:
    // MigrationInfo::new(3, "add_resource_tags", MIGRATION_003_ADD_RESOURCE_TAGS),
];

/// Get all migrations in order
/// 
/// This vector must be kept in order! Each migration will be applied
/// sequentially and tracked by rusqlite_migration using SQLite's user_version.
pub fn get_migrations() -> Vec<M<'static>> {
    MIGRATIONS_INFO
        .iter()
        .map(|info| M::up(info.sql))
        .collect()
}

/// Verify that migrations haven't been modified by checking hashes
/// 
/// This should be called after applying migrations to ensure integrity
pub fn verify_migration_hashes() -> Result<(), String> {
    for info in MIGRATIONS_INFO {
        let runtime_hash = calculate_migration_hash(info.sql);
        // Note: We calculate hash differently at compile time vs runtime
        // so we just verify the SQL hasn't changed between runs
        let stored_hash = info.hash;
        
        // For now, just log the hashes - in production you'd store these
        // in a migration_hashes table and verify against that
        tracing::debug!(
            "Migration {} ('{}') hash: compile={}, runtime={}", 
            info.version, info.name, stored_hash, runtime_hash
        );
    }
    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    use rusqlite::Connection;
    use rusqlite_migration::Migrations;

    #[test]
    fn test_migrations_valid() {
        // Verify migrations can be parsed and applied
        let migrations = Migrations::new(get_migrations());
        
        // Validate migration syntax
        migrations.validate().expect("Migrations should be valid");
        
        // Test application to in-memory database
        let mut conn = Connection::open_in_memory().unwrap();
        migrations.to_latest(&mut conn).expect("Migrations should apply successfully");
        
        // Verify the correct number of migrations were applied
        let applied_version: i32 = conn
            .pragma_query_value(None, "user_version", |row| row.get(0))
            .unwrap();
        
        let expected_version = get_migrations().len() as i32;
        assert_eq!(
            applied_version, expected_version,
            "Expected {} migrations to be applied, but user_version is {}",
            expected_version, applied_version
        );
        
        // Verify key tables exist
        let critical_tables = [
            "resources",
            "configuration", 
            "servers",
            "sessions",
            "retry_queue", // From migration 2
        ];
        
        for table in &critical_tables {
            let exists: bool = conn
                .prepare(&format!("SELECT name FROM sqlite_master WHERE type='table' AND name='{}'", table))
                .unwrap()
                .exists([])
                .unwrap();
            
            assert!(exists, "Critical table '{}' should exist", table);
        }
    }
    
    #[test]
    fn test_migration_hash_consistency() {
        // Verify that migration hashes are consistent
        for info in MIGRATIONS_INFO {
            let runtime_hash = calculate_migration_hash(info.sql);
            
            // The compile-time hash and runtime hash will differ due to different algorithms
            // But we can verify the SQL content hasn't changed by checking basic properties
            assert!(!info.sql.is_empty(), "Migration {} should not be empty", info.version);
            assert!(
                info.sql.trim().len() > 10, 
                "Migration {} seems too short to be valid SQL", 
                info.version
            );
            
            // Verify it looks like SQL (has at least one SQL keyword)
            let sql_keywords = ["CREATE", "ALTER", "DROP", "INSERT", "UPDATE", "DELETE", "PRAGMA", "INDEX"];
            let has_sql_keyword = sql_keywords.iter().any(|&keyword| 
                info.sql.to_uppercase().contains(keyword)
            );
            assert!(
                has_sql_keyword,
                "Migration {} doesn't appear to contain valid SQL keywords", 
                info.version
            );
            
            // Verify metadata
            assert!(!info.name.is_empty(), "Migration {} should have a name", info.version);
            assert!(info.hash != 0, "Migration {} should have a non-zero hash", info.version);
            
            // Log migration info for debugging
            eprintln!(
                "Migration {}: '{}' - Hash: {} (runtime: {})", 
                info.version, info.name, info.hash, runtime_hash
            );
        }
    }
    
    #[test] 
    fn test_migration_order() {
        // Ensure migrations are in sequential order
        let mut last_version = 0;
        for info in MIGRATIONS_INFO {
            assert!(
                info.version > last_version,
                "Migration {} is out of order (previous was {})",
                info.version,
                last_version
            );
            last_version = info.version;
        }
    }
}